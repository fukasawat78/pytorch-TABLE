{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TabTransformer\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup & Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/fukasawat78/.pyenv/versions/anaconda3-2019.10/lib/python3.7/site-packages/japanize_matplotlib/japanize_matplotlib.py:15: MatplotlibDeprecationWarning: \n",
      "The createFontList function was deprecated in Matplotlib 3.2 and will be removed two minor releases later. Use FontManager.addfont instead.\n",
      "  font_list = font_manager.createFontList(font_files)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import japanize_matplotlib\n",
    "plt.rcParams[\"figure.figsize\"] = 12, 8\n",
    "\n",
    "# Module\n",
    "import os\n",
    "import sys\n",
    "import pickle\n",
    "import datetime\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.gridspec as gridspec\n",
    "import os\n",
    "from torch.autograd import Variable\n",
    "import pandas as pd\n",
    "import math\n",
    "import sklearn.preprocessing as sk\n",
    "from tensorboardX import SummaryWriter\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn import metrics\n",
    "from sklearn.feature_selection import VarianceThreshold\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.linear_model import RidgeCV\n",
    "from sklearn.model_selection import train_test_split\n",
    "import random\n",
    "\n",
    "np.set_printoptions(threshold=np.inf)\n",
    "pd.set_option('display.max_columns', 1000)\n",
    "pd.set_option('display.max_rows', 1000)\n",
    "\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "\n",
    "from tab_transformer_pytorch import TabTransformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "cont_mean_std = torch.randn(10, 2)\n",
    "\n",
    "model = TabTransformer(\n",
    "    categories = (10, 10, 10, 10, 10, 10, 10, 10, 10, 10),\n",
    "    num_continuous = 10,\n",
    "    dim = 32,\n",
    "    dim_out = 2,\n",
    "    depth = 6,\n",
    "    heads = 10,\n",
    "    attn_dropout = 0.1,\n",
    "    ff_dropout = 0.1,\n",
    "    mlp_hidden_mults = (4, 2),\n",
    "    mlp_act = nn.ReLU(),\n",
    "    continuous_mean_std = cont_mean_std\n",
    ")\n",
    "\n",
    "X_categ = torch.randint(0, 10, size=(100, 10))\n",
    "X_cont = torch.randn(100, 10)\n",
    "\n",
    "X_categ_train = X_categ[:50]\n",
    "X_cont_train = X_cont[:50]\n",
    "X_categ_test = X_categ[50:]\n",
    "X_cont_test = X_categ[50:]\n",
    "\n",
    "y = torch.randint(0, 2, size=(1, 100))\n",
    "y_train = y[0, :50]\n",
    "y_test = y[0, 50:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 0.0\n",
      "loss: 0.3465735912322998\n",
      "loss: 0.457919180393219\n",
      "loss: 0.2616761751773343\n",
      "loss: 10.764729543117111\n",
      "loss: 7.441914598424091\n",
      "loss: 6.936234243189822\n",
      "loss: 5.417297808756145\n",
      "loss: 4.460556559854307\n",
      "loss: 3.7234547251476253\n",
      "loss: 3.182328378239942\n",
      "loss: 2.773656838635035\n",
      "loss: 2.4576300554192727\n",
      "loss: 2.2083009538061127\n",
      "loss: 2.008186304761007\n",
      "loss: 1.8451649259639318\n",
      "loss: 1.7106227077450316\n",
      "loss: 1.5983039809283606\n",
      "loss: 1.5035782694612227\n",
      "loss: 1.4229594702311923\n",
      "loss: 1.3537829500637426\n",
      "loss: 1.293984022824165\n",
      "loss: 1.2419430366512894\n",
      "loss: 1.1963751498415642\n",
      "loss: 1.1562506607483842\n",
      "loss: 1.1207365903278486\n",
      "loss: 1.089153281792495\n",
      "loss: 1.0609417654815367\n",
      "loss: 1.035638944045482\n",
      "loss: 1.012858528710974\n",
      "loss: 0.9922762532015507\n",
      "loss: 0.9736183031153425\n",
      "loss: 0.9566521861761671\n",
      "loss: 0.9411794724350964\n",
      "loss: 0.9270299793830882\n",
      "loss: 0.9140570825651054\n",
      "loss: 0.9021339095461876\n",
      "loss: 0.8911502321285473\n",
      "loss: 0.8810099142212292\n",
      "loss: 0.8716288046968905\n",
      "loss: 0.8629329887537825\n",
      "loss: 0.854857329753949\n",
      "loss: 0.8473442476896208\n",
      "loss: 0.8403426914016843\n",
      "loss: 0.8338072702177975\n",
      "loss: 0.8276975173713749\n",
      "loss: 0.8219772628374454\n",
      "loss: 0.8166140974011976\n",
      "loss: 0.8115789131047179\n",
      "loss: 0.8068455078833755\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.8068455078833755"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_optimizer(model, lr = 0.001, wd = 0.0):\n",
    "    parameters = filter(lambda p: p.requires_grad, model.parameters())\n",
    "    optim = torch.optim.Adam(parameters, lr=lr, weight_decay=wd)\n",
    "    return optim\n",
    "\n",
    "def train_model(model, optim, X_cat, X_cont, y):\n",
    "    model.train()\n",
    "    total = 1\n",
    "    sum_loss = 0\n",
    "    for batch, (x1, x2, y1) in enumerate(zip(X_cat, X_cont, y)):\n",
    "        x1 = x1.unsqueeze(0)\n",
    "        x2 = x2.unsqueeze(0)\n",
    "        y1 = y1.unsqueeze(0)\n",
    "        output = model(x1, x2)\n",
    "        #prob = F.softmax(out, dim=1)\n",
    "        #_, pred = torch.max(prob, 1)\n",
    "        loss = F.cross_entropy(output, y1)   \n",
    "        optim.zero_grad()\n",
    "        loss.backward()\n",
    "        optim.step()\n",
    "        total += batch\n",
    "        sum_loss += batch*(loss.item())\n",
    "        print(\"loss: {}\".format(sum_loss/total))\n",
    "    return sum_loss/total\n",
    "\n",
    "optim = get_optimizer(model, lr = 0.01, wd = 0.0)\n",
    "train_model(model, optim, X_categ_train, X_cont_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrix:\n",
      " [[30  0]\n",
      " [20  0]]\n",
      "Classification_report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.60      1.00      0.75        30\n",
      "           1       0.00      0.00      0.00        20\n",
      "\n",
      "    accuracy                           0.60        50\n",
      "   macro avg       0.30      0.50      0.37        50\n",
      "weighted avg       0.36      0.60      0.45        50\n",
      "\n",
      "Accuracy: 0.6\n",
      "AUC:0.5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/fukasawat78/.pyenv/versions/anaconda3-2019.10/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score, roc_curve, roc_auc_score\n",
    "\n",
    "model.eval()\n",
    "out = model(X_categ_test, X_cont_test)\n",
    "prob = F.softmax(out, dim=1)\n",
    "_, pred = torch.max(prob, 1)\n",
    "y_pred = pred.numpy()\n",
    "\n",
    "\n",
    "print(\"Confusion matrix:\\n {}\".format(confusion_matrix(y_test, y_pred)))\n",
    "print(\"Classification_report:\\n {}\".format(classification_report(y_test, y_pred)))\n",
    "print(\"Accuracy: {}\".format(accuracy_score(y_test, y_pred)))\n",
    "print(\"AUC:{}\".format(roc_auc_score(y_test, y_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
